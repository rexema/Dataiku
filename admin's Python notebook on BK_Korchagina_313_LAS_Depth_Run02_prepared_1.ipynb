{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "analyzedDataset": "BK_Korchagina_313_LAS_Depth_Run02_prepared",
    "creator": "admin",
    "createdOn": 1686832118143,
    "tags": [],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.7.17",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pylab inline"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd\nimport lasio\nimport os.path\nfrom func import LasReader\nfrom newdeg import NewDeg\nfrom newlat import NewLat\n\n\nhandle \u003d dataiku.Folder(\"My_folder\")\npath \u003d handle.get_path()\n\nwith open(os.path.join(path, \"LAS.las\")) as f:\n    las \u003d LasReader(f)\n    df \u003d pd.DataFrame(las.well_info, index\u003d[0,])\n    for col in df.columns:\n        if \u0027NULL\u0027 in col:\n            del df[col]\n        if \u0027 \u0027 in col:\n            del df[col]\nresult \u003d df.replace(\u0027-999.25\u0027, \u0027\u0027)\n# Создаю регулярные выражения для поиска координат\nreg_expr \u003d r\u0027(\\d+�\\s\\d+.\\s\\d+.\\d+.\\s[N])\u0027\nreg_expr2 \u003d r\u0027(\\d+�\\s\\d+.\\s\\d+.\\d+.\\s[E])\u0027\nreg_expr3 \u003d r\u0027(^\\d+.\\d+)\u0027\nreg_expr4 \u003d r\u0027(\\?+)\u0027\n\nlong_lst \u003d list(result[\u0027LONG\u0027])\nlati_lst \u003d list(result[\u0027LATI\u0027])\nlong_lst2 \u003d long_lst.copy()\nlati_lst2 \u003d lati_lst.copy()\n\nnew_deg \u003d  NewDeg(reg_expr3, long_lst2)\nnew_deg2 \u003d NewDeg(reg_expr3, lati_lst2)\n\nnew_lati \u003d NewLat(reg_expr, new_deg2.lst)\nnew_long \u003d NewLat(reg_expr2, new_deg.lst)\n\nresult[\u0027LATI\u0027]\u003d result[\u0027LATI\u0027].replace(lati_lst,new_lati.lst)\nresult[\u0027LONG\u0027] \u003d result[\u0027LONG\u0027].replace(long_lst, new_long.lst)\n\nfinal_data \u003d result.dropna(thresh\u003dresult.shape[0] //2, axis\u003d1)\nfinal_data\u003dfinal_data.replace(to_replace\u003dreg_expr4, value\u003d\u0027mm\u0027, regex\u003dTrue)\n\n    \ndataset_name \u003d \u0027test5\u0027\n\n# Get a handle to the current project\nclient \u003d dataiku.api_client()\nproject \u003d client.get_project(dataiku.default_project_key())\n\n# Create a SQL dataset (you can create other types by specifying different parameters for the with_store_into method)\n# Documentation here: https://doc.dataiku.com/dss/latest/python-api/datasets-other.html#programmatic-creation-and-setup-managed-datasets\n# Note that documentation shows project.new_managed_dataset which is incorrect\nbuilder \u003d project.new_managed_dataset_creation_helper(dataset_name)\nbuilder.with_store_into(\"las\")\nbuilder.create() \n\n# Write dataframe to dataset\ndataiku.Dataset(dataset_name).write_with_schema(final_data)\n    \n\n\n\n"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}